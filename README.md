## ğŸ‘‹ Hi, I'm Kevin King!
AI Researcher | Machine Learning Engineer | Human-AI Interaction Enthusiast

ğŸš€ Passionate about AI-driven behavioral modeling, multimodal learning, and human-computer interaction, I specialize in machine learning, reinforcement learning, and AI applications in AR/VR. My work focuses on building AI-powered tools for behavioral analysis, human-agent collaboration, and interactive experiences.

## ğŸ” Currently exploring:

- AI-driven AR/VR simulations and player behavior analysis
- AI for emotion-aware computing and multimodal learning (audio, video, text)
- Generative AI & LLMs for code analysis and autonomous agents
- Reinforcement learning applied to human-agent collaboration

## ğŸ› ï¸ Projects

### ğŸ­ Human-State Aware AI for Adaptive Technology (Simulations using AR/VR/Desktop)

ğŸ”¹ Developed an AI model for recognizing human emotions from physiological and behavioral signals in VR environments.

ğŸ”¹ Used EEG, eye-tracking, and reinforcement learning to adapt virtual scenarios based on user state.

ğŸ”¹ Tech: Unity, Python, PyTorch, TensorFlow

![](https://github.com/kingkw1/public_media/blob/main/gifs/bomb_defusal_looping.gif)

- <a href="https://ieeexplore.ieee.org/document/10394167"> Granger Leadership in a Novel Dyadic Search Paradigm </a>
- <a href="https://openaccess.cms-conferences.org/publications/book/978-1-964867-13-7/article/978-1-964867-13-7_5"> Using Multi-Modal Physiological Markers and Latent States to Understand Team Performance and Collaboration </a>
- <a href="https://ieeexplore.ieee.org/document/10394383"> Latent State Synchronization in Dyadic Partners using EEG </a>
- <a href="https://iopscience.iop.org/article/10.1088/1741-2552/acee20/pdf"> Decoding neural activity to assess individual latent state in ecologically valid contexts </a>

### ğŸ“Š Multimodal AI for Behavioral Analysis

ğŸ”¹ Created machine learning models to analyze team dynamics, integrating speech, video, and physiological data for real-time insights.

ğŸ”¹ Used deep learning, NLP, and computer vision to study human interactions.

ğŸ”¹ Tech: Python, Hugging Face, TensorFlow, Pandas, SciPy

- <a href="https://ieeexplore.ieee.org/document/10394167"> Granger Leadership in a Novel Dyadic Search Paradigm </a>
- <a href="https://aaquibtabrez.github.io/assets/pdf/publications/xhri24.pdf"> Hierarchical Multi-Agent Reinforcement Learning with Explainable Decision Support for Human-Robot Teams </a>

### ğŸ¤ Codebase Chatbot (LLM-Powered Repository Analysis)

ğŸ”¹ AI-powered chatbot that analyzes codebases, extracts key functions, and generates insightful recommendations.

ğŸ”¹ Uses LLMs, embeddings, and FAISS-based retrieval for efficient search.

ğŸ”¹ Tech: Python, Flask, FAISS, PyTorch, OpenAI API, Ollama

### ğŸ§ Neural Engineering for Neurorehabilitation

ğŸ”¹ Developed neuromodulation techniques to restore motor function, using dorsal root ganglia (DRG) microstimulation to evoke postural responses and closed-loop neuromuscular stimulation for grasp force control.

ğŸ”¹ Investigated somatosensory feedback restoration through microstimulation and designed a wearable textile-based electrode system to regulate precise finger movements in individuals with quadriplegia.

ğŸ”¹ Tech: Python, MATLAB, Signal Processing, Neural Interfaces, Closed-Loop Control

![](https://media.springernature.com/full/springer-static/image/art%3A10.1186%2Fs42234-019-0034-y/MediaObjects/42234_2019_34_Fig3_HTML.png?as=webp)

- <a href="https://link.springer.com/article/10.1186/s42234-019-0034-y"> Closed-loop neuromuscular electrical stimulation using feedforward-feedback control and textile electrodes to regulate grasp force in quadriplegia </a>
- <a href="https://iopscience.iop.org/article/10.1088/1741-2552/acee20/pdf"> DRG microstimulation evokes postural responses in awake, standing felines </a>


## ğŸ“Œ Skills & Tools

ğŸ’» Programming: Python, C++, C#, MATLAB, R, Linux, Git

ğŸ“Š Machine Learning: PyTorch, TensorFlow, Scikit-learn, OpenCV, Hugging Face

ğŸ•¶ï¸ AR/VR & Simulation: Unity, Unreal Engine, Reinforcement Learning

ğŸ§ Multimodal AI: Speech & Audio Processing, Emotion Recognition, Video Analysis


## ğŸ“£ Let's Collaborate!

If you're interested in AI, reinforcement learning, multimodal ML, or AR/VR research, let's connect!

ğŸ‘‰ <a href="linkedin.com/in/kingkw1"> LinkedIn </a> | ğŸ“« king.kevin.w@gmail.com
