## 👋 Hi, I'm Kevin King!
AI Researcher | Machine Learning Engineer | Human-AI Interaction Enthusiast

🚀 Passionate about AI-driven behavioral modeling, multimodal learning, and human-computer interaction, I specialize in machine learning, reinforcement learning, and AI applications in AR/VR. My work focuses on building AI-powered tools for behavioral analysis, human-agent collaboration, and interactive experiences.

## 🔍 Currently exploring:

- Generative AI & LLMs for code analysis and autonomous agents
- AI for emotion-aware computing and multimodal learning (audio, video, text)
- Reinforcement learning applied to human-agent collaboration
- AI-driven AR/VR simulations and player behavior analysis  

## 🛠️ Projects

### Human-State Aware AI for Adaptive Technology (Simulations using AR/VR/Desktop)

🔹 Developed an AI model for recognizing human emotions from physiological and behavioral signals in VR environments.

🔹 Used EEG, eye-tracking, and reinforcement learning to adapt virtual scenarios based on user state.

🔹 Tech: Unity, Python, PyTorch, TensorFlow

- <a href="https://ieeexplore.ieee.org/document/10394167"> Granger Leadership in a Novel Dyadic Search Paradigm </a>
- <a href="https://openaccess.cms-conferences.org/publications/book/978-1-964867-13-7/article/978-1-964867-13-7_5"> Using Multi-Modal Physiological Markers and Latent States to Understand Team Performance and Collaboration </a>
- <a href="https://ieeexplore.ieee.org/document/10394383"> Latent State Synchronization in Dyadic Partners using EEG </a>
- <a href="https://iopscience.iop.org/article/10.1088/1741-2552/acee20/pdf"> Decoding neural activity to assess individual latent state in ecologically valid contexts </a>

### Multimodal AI for Behavioral Analysis

🔹 Created machine learning models to analyze team dynamics, integrating speech, video, and physiological data for real-time insights.

🔹 Used deep learning, NLP, and computer vision to study human interactions.

🔹 Tech: Python, Hugging Face, TensorFlow, Pandas, SciPy

- <a href="https://ieeexplore.ieee.org/document/10394167"> Granger Leadership in a Novel Dyadic Search Paradigm </a>
- <a href="https://aaquibtabrez.github.io/assets/pdf/publications/xhri24.pdf"> Hierarchical Multi-Agent Reinforcement Learning with Explainable Decision Support for Human-Robot Teams </a>

### Codebase Chatbot (LLM-Powered Repository Analysis)

🔹 AI-powered chatbot that analyzes codebases, extracts key functions, and generates insightful recommendations.

🔹 Uses LLMs, embeddings, and FAISS-based retrieval for efficient search.

🔹 Tech: Python, Flask, FAISS, PyTorch, OpenAI API, Ollama

## 📌 Skills & Tools

💻 Programming: Python, C++, C#, MATLAB, R, Linux, Git

📊 Machine Learning: PyTorch, TensorFlow, Scikit-learn, OpenCV, Hugging Face

🕶️ AR/VR & Simulation: Unity, Unreal Engine, Reinforcement Learning

🎧 Multimodal AI: Speech & Audio Processing, Emotion Recognition, Video Analysis


## 📣 Let's Collaborate!

If you're interested in AI, reinforcement learning, multimodal ML, or AR/VR research, let's connect!

👉 <a href="linkedin.com/in/kingkw1"> LinkedIn </a> | ✉️ king.kevin.w@gmail.com
