## ğŸ‘‹ Hi, I'm Kevin King!
AI Researcher | Machine Learning Engineer | Human-AI Interaction Enthusiast

ğŸš€ I specialize in **human-centered AI**, **multimodal learning**, and **real-time behavior modeling** â€” building intelligent systems that sense, adapt to, and collaborate with people. My work blends machine learning, affective computing, and neuroadaptive technology across simulations, telehealth, and robotics.

## ğŸ” Currently exploring:

* **Emotion-aware AI** for healthcare, collaboration, and learning
* **AI for behavior-adaptive simulations** (AR/VR/Desktop)
* **LLMs + multimodal input** for interactive autonomous agents
* **Reinforcement learning** in mixed human-agent teams

---

## ğŸ› ï¸ Featured Projects

### â¤ï¸ AffectLink: Multimodal Emotion Consistency Tracking for Telehealth

**Hackathon finalist | HP & NVIDIA Developer Challenge 2025**

ğŸ”¹ Built a privacy-preserving system for real-time **emotion inconsistency detection** in telehealth.
ğŸ”¹ Combines **facial expression**, **vocal tone**, and **spoken text** into an **Emotional Consistency Index (ECI)**.
ğŸ”¹ Runs locally using HP AI Studio and NVIDIA RTX acceleration for full patient data security.
ğŸ”¹ Tech: Whisper (ASR), DeepFace, Hugging Face Transformers, Streamlit, MLflow, OpenCV

![](https://github.com/kingkw1/AffectLink/blob/main/assets/thumbnail.png)

* [ğŸ“ GitHub Repository](https://github.com/kingkw1/AffectLink)
* [ğŸ¥ Hackathon Demo Video](https://www.youtube.com/watch?v=rzp9CGChHJ4)
---

### ğŸ­ Human-State Aware AI for Adaptive Technology (Simulations using AR/VR/Desktop)

ğŸ”¹ Developed an AI model for recognizing human emotions from physiological and behavioral signals in VR environments.

ğŸ”¹ Used EEG, eye-tracking, and reinforcement learning to adapt virtual scenarios based on user state.

ğŸ”¹ Tech: Unity, Python, PyTorch, TensorFlow

![](https://github.com/kingkw1/public_media/blob/main/gifs/bomb_defusal_looping.gif)

- <a href="https://ieeexplore.ieee.org/document/10394167"> Granger Leadership in a Novel Dyadic Search Paradigm </a>
- <a href="https://openaccess.cms-conferences.org/publications/book/978-1-964867-13-7/article/978-1-964867-13-7_5"> Using Multi-Modal Physiological Markers and Latent States to Understand Team Performance and Collaboration </a>
- <a href="https://ieeexplore.ieee.org/document/10394383"> Latent State Synchronization in Dyadic Partners using EEG </a>
- <a href="https://iopscience.iop.org/article/10.1088/1741-2552/acee20/pdf"> Decoding neural activity to assess individual latent state in ecologically valid contexts </a>
---

### ğŸ“Š Multimodal AI for Behavioral Analysis

ğŸ”¹ Created machine learning models to analyze team dynamics, integrating speech, video, and physiological data for real-time insights.

ğŸ”¹ Used deep learning, NLP, and computer vision to study human interactions.

ğŸ”¹ Tech: Python, Hugging Face, TensorFlow, Pandas, SciPy

- <a href="https://ieeexplore.ieee.org/document/10394167"> Granger Leadership in a Novel Dyadic Search Paradigm </a>
- <a href="https://aaquibtabrez.github.io/assets/pdf/publications/xhri24.pdf"> Hierarchical Multi-Agent Reinforcement Learning with Explainable Decision Support for Human-Robot Teams </a>
---

### ğŸ¤ Codebase Chatbot (LLM-Powered Repository Analysis)

ğŸ”¹ AI-powered chatbot that analyzes codebases, extracts key functions, and generates insightful recommendations.

ğŸ”¹ Uses LLMs, embeddings, and FAISS-based retrieval for efficient search.

ğŸ”¹ Tech: Python, Flask, FAISS, PyTorch, OpenAI API, Ollama

---

### ğŸ§ Neural Engineering for Neurorehabilitation

ğŸ”¹ Developed neuromodulation techniques to restore motor function, using dorsal root ganglia (DRG) microstimulation to evoke postural responses and closed-loop neuromuscular stimulation for grasp force control.

ğŸ”¹ Investigated somatosensory feedback restoration through microstimulation and designed a wearable textile-based electrode system to regulate precise finger movements in individuals with quadriplegia.

ğŸ”¹ Tech: Python, MATLAB, Signal Processing, Neural Interfaces, Closed-Loop Control

![](https://media.springernature.com/full/springer-static/image/art%3A10.1186%2Fs42234-019-0034-y/MediaObjects/42234_2019_34_Fig3_HTML.png?as=webp)

- <a href="https://link.springer.com/article/10.1186/s42234-019-0034-y"> Closed-loop neuromuscular electrical stimulation using feedforward-feedback control and textile electrodes to regulate grasp force in quadriplegia </a>
- <a href="https://iopscience.iop.org/article/10.1088/1741-2552/acee20/pdf"> DRG microstimulation evokes postural responses in awake, standing felines </a>
---

## ğŸ“Œ Skills & Tools

ğŸ’» **Programming**: Python, C++, MATLAB, C#, R

ğŸ“Š **Machine Learning**: PyTorch, TensorFlow, Hugging Face, Scikit-learn, FAISS

ğŸ•¶ï¸ **AR/VR & Simulation**: Unity, Unreal Engine, Custom Reinforcement Learning

ğŸ§ **Multimodal AI**: Speech & Audio Processing, Emotion Recognition, Multimodal Synchrony,

## ğŸ“£ Let's Collaborate!

If you're interested in AI, reinforcement learning, multimodal ML, or AR/VR research, let's connect!

ğŸ‘‰ <a href="linkedin.com/in/kingkw1"> LinkedIn </a> | ğŸ“« king.kevin.w@gmail.com
